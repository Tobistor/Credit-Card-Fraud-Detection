{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-f89f71ebbfb2>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-f89f71ebbfb2>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    MAX ROUNDS = 1000 #lgb iterations\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "RFC_METRIC = 'gini' #metrics used for RandomForestClasifier\n",
    "NUM_ESTIMATORS = 100 #number of estimators used for RandomForestClassifier\n",
    "NO_JOBS = 4 #number of parallel jobs used for RandomForestClassifier\n",
    "\n",
    "#Train/validation/test split\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "\n",
    "#CROSS-VALIDATION\n",
    "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
    "\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "MAX ROUNDS = 1000 #lgb iterations\n",
    "EARLY_STOP = 50 #lgb early stop\n",
    "OPT_ROUNDS = 1000 #To be adjusted based on best validation rounds\n",
    "VERBOSE_EVAL = 50 #Print out metric result\n",
    "\n",
    "IS_LOCAL = False\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bab0589d61fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "RFC_METRIC = 'gini' #metrics used for RandomForestClasifier\n",
    "NUM_ESTIMATORS = 100 #number of estimators used for RandomForestClassifier\n",
    "NO_JOBS = 4 #number of parallel jobs used for RandomForestClassifier\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "#Train/validation/test split\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "\n",
    "#CROSS-VALIDATION\n",
    "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
    "\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "MAX_ROUNDS = 1000 #lgb iterations\n",
    "EARLY_STOP = 50 #lgb early stop\n",
    "OPT_ROUNDS = 1000 #To be adjusted based on best validation rounds\n",
    "VERBOSE_EVAL = 50 #Print out metric result\n",
    "\n",
    "IS_LOCAL = False\n",
    "filename = '/Users/Mac/Desktop/creditcard.csv' \n",
    "cc_data = pd.read_csv(filename)\n",
    "#check the data\n",
    "#cc_data.head()\n",
    "#cc_data.tail()\n",
    "print(\"CreditCard data provided has rows:\",cc_data.shape[0], \"columns:\", cc_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_for_missing_data = cc_data.isnull().sum()\n",
    "check_for_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#View Dataframe\n",
    "df = pd.DataFrame(cc_data)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Steps\n",
    "# Try to understand and interprete the dataset (cc_data).\n",
    "# Play around data visualization using Seaborn and Matplotlib.\n",
    "# Decide on  Machine learning Model to use and train with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictive Model\n",
    "target = 'Class'\n",
    "predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n",
    "             'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n",
    "             'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n",
    "             'Amount']\n",
    "\n",
    "#Define train, validation and test sets\n",
    "train_cc, test_cc = train_test_split(cc_data, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True )\n",
    "train_cc, valid_cc = train_test_split(train_cc, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )\n",
    "\n",
    "#Using RandomForestClassifier model\n",
    "clf = RandomForestClassifier(n_jobs=NO_JOBS,random_state=RANDOM_STATE,criterion=RFC_METRIC,n_estimators=NUM_ESTIMATORS,verbose=False)\n",
    "\n",
    "#Train the RandomForestClassifier using the train_df data and fit function\n",
    "clf.fit(train_cc[predictors], train_cc[target].values)\n",
    "#---Think there was an out here---\n",
    "\n",
    "#Let's now predict the target values for the valid_df data, using predict function.\n",
    "preds = clf.predict(valid_cc[predictors])\n",
    "\n",
    "#Visualize the features importance\n",
    "#FEATURES IMPORTANCE\n",
    "#To do come back to this for review, we are commentin lines 25 - 44\n",
    "#tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importance})\n",
    "#tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "#plt.figure(figsize = (7,4))\n",
    "#plt.title('Features importance',fontsize=14)\n",
    "#s = sns.barplot(x='Feature', y='Feature importance', data=tmp)\n",
    "#s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "#plt.show()\n",
    "\n",
    "#CONFUSION MATRIX\n",
    "#Let's show a confusion matrix for result we obtained\n",
    "\n",
    "#cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "#fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
    "#sns.heatmap(cm,\n",
    " #          xticklabels=['Not Fraud', 'Fraud'],\n",
    "  #         yticklables=['Not Fraud', 'Fraud'],\n",
    "   #        annot=True,ax=ax1,\n",
    "    #       linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
    "#plt.title('Confusion Matrix', fontsize=14)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528641975628091"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valid_cc[target].values, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ROC-AUC score obtained with RandomForrestClassifier is 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier\n",
    "AdaBoostClassifier stands for Adaptive Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's set the parameter for the model and initialize the model\n",
    "clf = AdaBoostClassifier(random_state=RANDOM_STATE,\n",
    "                        algorithm='SAMME.R',\n",
    "                        learning_rate=0.8,\n",
    "                        n_estimators=NUM_ESTIMATORS)\n",
    "#FIT THE MODEL.\n",
    "#Let's fit the model\n",
    "clf.fit(train_cc[predictors], train_cc[target].values)\n",
    "\n",
    "#PREDICT THE TARGET VALUES\n",
    "#Let's now predict the target values for the valid_df data, using predict function.\n",
    "preds = clf.predict(valid_cc[predictors])\n",
    "\n",
    "#FEATURES IMPORTANCE\n",
    "#Let's see also the features importance.\n",
    "#To do come back to this for review, we are commentin lines 17 - 23\n",
    "#tmp = pd.DataFrame({'Feature':predictors, 'Feature importance': clf.feature_importances_})\n",
    "#tmp = tmp.sort_values(by='Feature importance', ascending=False)\n",
    "#plt.figure(figsize = (7,4))\n",
    "#plt.title('Features importance', fontsize=14)\n",
    "#s = sns.barplot(x='Feature',y='feature importance',data=tmp)\n",
    "#s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate also the ROC-AUC\n",
    "ROC AUC score is equivalent to calculating the rank correlation between predictions and targets. \n",
    "From an interpretation standpoint, it is more useful because it tells us that this metric shows how good at ranking predictions your model is. \n",
    "It tells you what is the probability that a randomly chosen positive instance is ranked higher than a randomly chosen negative instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332343604519027"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "#fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
    "#sns.heatmap(cm\n",
    " #          xticklabels=['Not Fraud', 'Fraud'],\n",
    "  #         yticklabels=['Not Fraud', 'Fraud'],\n",
    "   #        annot=True,ax=ax1,\n",
    "    #       linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
    "#plt.title('Confusion Matrix', fontsize=14)\n",
    "#plt.show()\n",
    "\n",
    "#Let's calculate also the ROC-AUC\n",
    "#Area Under Curve\n",
    "roc_auc_score(valid_cc[target].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoostClassifier\n",
    "CatBoostClassifier is a gradient boosting for decision trees algorithm with support for handling categorical data\n",
    "\n",
    "Let's set the parameters for the model and initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-327a112a602b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m clf = CatBoostClassifier(iterations=500,\n\u001b[1;32m      3\u001b[0m                         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AUC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "clf = CatBoostClassifier(iterations=500,\n",
    "                        learning_rate=0.02,\n",
    "                        depth=12,\n",
    "                        eval_metric='AUC',\n",
    "                        random_seed = RANDOM_STATE,\n",
    "                        bagging_temperature = 0.2,\n",
    "                        od_type='Iter',\n",
    "                        metric_period = VERBOSE_EVAL,\n",
    "                        od_wait=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target values\n",
    "#Let's now predict the target values for the val_df data, using predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Importance\n",
    "#Let's see also the features importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "#Let's visualize the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    plt.title('Confusion Matrix', fontsize=14)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(valid_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
    "     sns.heatmap(cm,\n",
    "                xticklabels=['Not Fraud', 'Fraud'],\n",
    "                yticklabels=['Not Fraud', 'Fraud'],\n",
    "                annot=True,ax=ax1,\n",
    "                linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "#Let's calculate also the ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332343604519027"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area Under Curve\n",
    "roc_auc_score(valid_cc[target].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost is a gradient boosting algorithm\n",
    "#Let's prepared the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the model\n",
    "\n",
    "We initialize the DMatrix objects for training and valid, starting from the datasets. We also set some of the parameters used for the model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-3953bfb40e19>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-3953bfb40e19>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    params['random_state'] RANDOM_STATE\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Prepare the train and valid datasets\n",
    "dtrain = xgb.DMatrix(train_df[predictors], train_cc[target].values)\n",
    "dvalid = xgb.DMatrix(valid_df[predictors], valid_df[target].values)\n",
    "dtest = xgb.DMatrix(test_df[predictors], test_cc[target].values)\n",
    "\n",
    "#what to monitor (in this case, **train** and **valid**)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "#Set xgboost parameters\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.039\n",
    "params['silent'] =True\n",
    "params['max-depth'] = 2\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.9\n",
    "params['eval_metrics'] = 'auc'\n",
    "params['random_state'] RANDOM_STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-43928a9ffd5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = xgb.train(params,\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mMAX_ROUNDS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEARLY_STOP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params,\n",
    "                 dtrain,\n",
    "                 MAX_ROUNDS,\n",
    "                 watchlist,\n",
    "                 early_stopping_rounds=EARLY_STOP,\n",
    "                 maximize=True,\n",
    "                 Verbose_eval=VERBOSE_EVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(ncols=1, figsize=(8,5))\n",
    "xgb.plot_importance(model, height=0.8, title=\"Features importance (XGBoost)\", ax=ax, color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test set\n",
    "We used the train and validation sets for training and validation. We will use the trained model now to predict the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area Under Curve\n",
    "Let's calculate ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_df[target].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM\n",
    "Another gradient boosting Algorithm is LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model Parameters\n",
    "Let's start the parameters for the model. We will use these parameters only for the first lgb model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric':'auc',\n",
    "    'learning_rate':0.05,\n",
    "    'num_leaves': 7, #we should let it be smaller than 2^(max depth)\n",
    "    'max_depth': 4, # -1 means no limit\n",
    "    'min_child_samples': 100, #Minimum number of data needed in a child(min_data_in_leaf)\n",
    "    'max_bin': 100, #Number of bucketed bin for feature values\n",
    "    'subsample': 0.9, #Subsample ratio of columns when construction each tree.\n",
    "    'subsample_freq':1, #frequency of subsample, <=0 means no enable\n",
    "    'colsample_bytree': 0.7, #Subsample ratio of columns when construction each tree.\n",
    "    'min_child_weight': 0, #Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'min_split_gain': 0, #Lambda_L1, Lambda_L2 and min_gain_to_split to regularization\n",
    "    'nthread': 8,\n",
    "    'verbose': 0,\n",
    "    'scale_pos_weight':150, # because training data is extremely unbalanced\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the model\n",
    "Let's prepare the model, creating the Datasets data structures from the train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(train_df[predictors].values,\n",
    "                    label=train_df[target].values,\n",
    "                    feature_name=predictors)\n",
    "dvalid = lgb.Data(valid_df[predictors].values,\n",
    "                 label=valid_df[target].values,\n",
    "                 feature_name=predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model\n",
    "Let's run the model, using the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_results = {}\n",
    "model = lgb.train(params,\n",
    "                 dtrain,\n",
    "                 valid_sets=[dtrain,dvalid],\n",
    "                 valid_names=['train','valid'],\n",
    "                 evals_results=evals_results,\n",
    "                 num_boost_round=MAX_ROUNDS,\n",
    "                  early_stopping_rounds=2*EARLY_STOP,\n",
    "                 verbose_eval=VERBOSE_EVAL,\n",
    "                 feval=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax) = plt.subplots(ncols=1, figsize=(8,5))\n",
    "lgb.plot_importance(model, height=0.8, title=\"Features importance (LightGBM)\", ax=ax,color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-56bc3850f4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Lets calculate the ROC-AUC score for the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_df[predictors])\n",
    "\n",
    "#Lets calculate the ROC-AUC score for the prediction\n",
    "roc_auc_score(test_df[target].values, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
